# Numerical Analysis

Use the following links to navigate to the start of the sections

[1. Collaborative Discussion 1](#collaborative-discussion-1)

[2. Collaborative Discussion 2](#collaborative-discussion-2)

[3. End of Module Assessment 1: Statistical Analysis Presentation](#end-of-module-assessment-1-statistical-analysis-presentation)

[4. End of Module Assessment 2: Individual Reflection](#end-of-module-assessment-2-individual-reflection)


## Learning outcomes

### In this module I shall:

* Develop a systematic understanding of foundational mathematical principles and methods, as well as core and specialised concepts underpinning computing logic.

* Understand the foundation for the development and application of programming and data-driven techniques, from both a theoretical and practical viewpoint.

* Facilitate the ability to interpret the results generated when using these data science and ai tools.

* Gain an understanding of the real-world applications of these computational tools, and contemporary issues related to these computational techniques.

* The opportunity to take a reflective and independent approach to the learning process.

### On completion of this module I will be able to:

* Demonstrate systematic understanding of the key mathematical and statistical concepts and techniques which underpin mechanisms in Data Science and AI.

* Apply mathematical and statistical methods in these fields to help in the decision-making process.

* Critically evaluate the use of statistical analysis and the numeric interpretation of results as aids in the decision-making process.

* Critically appraise and present results of a statistical analysis to a diverse audience.


## Collaborative Discussion 1

### Initial & summary posts

**Imagine you have submitted a paper for publication (see Brown, 1994 in this week’s reading list). The editor has returned his comments saying that he is willing to accept the paper for publication on condition that Table 2 (see Brown, 1994) is changed. He feels that ‘it is difficult for the reader to understand, contains too much information and is too large.’  You now have to redo the table 2 and present some of the findings using plots and present your results in the forum. Reflect also upon your experiences of undertaking this task and what you have learnt.**

**Initial Post**

Let me open this discussion forum with my experience when dealing with the activity of Unit 5 and in particular with the Table 2 of the article.  

Table 2 is quite informative as to the opinions of the general practitioners in Nottinghamshire on intrapartum care.  However, it is too cumbersome to read and not so easy to understand.  My approach would be quite different.  Let me describe to you how I reflected on this.  

Table 2 refers to 24 statements to which general practitioners have expressed their agreement/disagreement/no opinion.  At first, I thought it would be a good idea to take those statements with a rate of approval above 50% to showcase the findings of the research.  However, the statements which had got above the threshold of 50% were 11, so it would not make much difference for the visualisation of the data.  

Then, I chose the statements which equal to or go above 75% of the approval.  I found that 5 statements had got this percentage.   To illustrate the 5 most common opinions, I chose the horizontal bar chart (please see below) as I think it better highlights the message of the research.  Nevertheless, for the sake of the research I would put the existing Table 2 in the annex, so a more interested reader might be able to find more information.

![image](https://github.com/user-attachments/assets/a92d0780-6d7c-4852-bcde-b45de2d0f9d4)


In addition, I would also choose a couple of statements which did not get the threshold of 75% but they are quite popular among practitioners and would try to make my point by illustrating the whole spectrum of responses (Agree/Disagree/No opinion).  For example, I would take the statement on the fear of litigation and make a 'doughnut' (please see below) to highlight that only 20% of the practitioners seemed not to be afraid of litigation.  

![image](https://github.com/user-attachments/assets/d742e33a-0d40-4cc5-aef3-73009221e99e)


In brief, to better highlight my arguments, I would choose the most popular statements and create a graph (preferably a bar chart or a pie chart).  I think that for the abovementioned case boxplots, scatter plots, line graphs etc would not be suitable.  

I would also choose a couple of interesting statements that I would like to refer to in my analysis and try to present the percentages of Agree/Disagree/No opinion, using a pie chart/doughnut.  I would go for the simplicity as the simplest plots/graphs seem to be effective in conveying the message and are easy-to understand for the reader.


**Summary Post**

To provide a good visualisation of the Table 2, I took a different approach from the one taken by the authors of the article.  As Table 2 refers to 24 statements to which general practitioners have expressed their agreement/disagreement/no opinion, I thought it would be a good idea to take only those statements with a rate of approval above 75% to better showcase the findings of the research.   

I found that 5 statements had got this percentage.   To illustrate the 5 most common opinions, I chose the horizontal bar chart as I think it better highlights the message of the research.  Nevertheless, for the sake of the research I would put the existing Table 2 in the annex, so a more interested reader might be able to find more information.

In addition, I would also choose a couple of statements which did not get the threshold of 75% but they are quite popular among practitioners and would try to make my point by illustrating the whole spectrum of responses (Agree/Disagree/No opinion).  For example, I would take the statement on the fear of litigation and make a 'doughnut' to highlight that only 20% of the practitioners seemed not to be afraid of litigation.  

In brief, to better highlight my arguments, I would choose the most popular statements and create a graph (preferably a bar chart or a pie chart).  I think that for the abovementioned case boxplots, scatter plots, line graphs etc would not be suitable.  

I would also choose a couple of interesting statements that I would like to refer to in my analysis and try to present the percentages of Agree/Disagree/No opinion, using a pie chart/doughnut.  I would go for the simplicity as the simplest plots/graphs seem to be effective in conveying the message and are easy-to understand for the reader.

My peers with whom I had the opportunity to exchange some ideas tested different methods equally valid and effective.  In brief, Elias opted for using AI-enabled tools to make a very easy to read graph which was quite nice to see.  As for Jaco, I particularly liked the approach of keeping the 'No opinion' option in the graph as according to him, this piece of information is quite worth telling.  For example, if practitioners overwhelmingly decline to answer a question, then the researcher has to understand the reason behind this behaviour.  So, both methods developed by my two peers are worth keeping in mind.  

As for the inclusion or not of the ‘No opinion’ answers when calculating the percentages, some researchers opt for discarding them and choose to measure only the valid ones ‘Agree’ and ‘Disagree’.  Nevertheless, there are some others who prefer to give a full account of the 'Agree', 'Disagree' and No opinion' answer options and they calculate the percentage of all these options.  In my opinion, both approaches can be used depending on the findings of the research and on whether we wish to give a detailed or less detailed account of the data we have collected.

To sum up, I opted for simplicity by highlighting only the most popular statements and by putting the whole table with all the details in an annex.  Another method was to provide very descriptive graph with vivid colours to highlight the differences of popularity among practitioners of the 24 statements.  Last but not least, it could be another option to focus on the 'Agree' rate and the rate of the 'No opinion' as this aspect could be very informative for our understanding of the research findings.  

In all the abovementioned cases, after the graphs are provided, it depends on the storyteller to frame the message they want to convey to the readers.  So, I think that the visualisation may at the end of the day help the storyteller develop a certain analysis and narrative for their research.


### Response to my peers' posts


Hello Elias,

it's been quite a while since the last time we spoke to each other via the discussion forum.  I was quite impressed with what you did considering the complexity of the dataset (a lot of statements, percentages etc).  

As you say, putting everything in one table/spreadsheet is not ideal from a visualisation point of view.  Nevertheless, I strongly believe that such information should be part of the research paper as it provides a detailed information on the opinions of the consulted individuals.

Taking advantage of the AI capabilities as for the visualisation of the data seemed to me quite smart from your side.  Why should we not try prompting the AI tool (ChatGPT) when we wish to create effective and though-provoking graphs for our research purposes? 

As you may have noticed, I opted for a different way of highlighting interesting research data.  In my case, I chose the most popular statements and produced plots/bars/doughnut using Excel.  At the end of the day, when you read a paper you will not understand the rationale of the research unless you visualise the most significant arguments/points.  So I chose the most popular statements and made some graphs.  

Having said the above, for the sake of the objectivity of the research, I would put the whole table with the data as an Annex to the paper, so the reader who would be more interested to look at the details should be able to do so.


Dear Jaco,

I very much liked your approach in depicting the research data.  First, you tried to summarise the statements, so they become more reader friendly.   Then, I particularly liked your reasoning as for the inclusion in your graph of the answer options 'Agree' and 'No opinion'.  

In fact, I have been thinking quite a while about how to treat the component 'No opinion', as it may give us valuable information.  For example, if 40% of the respondents declined to give a straightforward answer, then it might be a proof that something was wrong with the question itself or with the issue it raised.  However, it is equally intriguing how you deal with the 'No opinion' component when calculating the percentages.  Do you take it into account or not?

Some researchers opt for discarding 'No opinion' answers and calculate only the valid ones.  Nevertheless, there are some others who prefer to give a full account of the 'Agree', 'Disagree' and No opinion' answer options.  

In my opinion, both approaches can be used depending on the findings of the research and whether we wish to give a detailed or less detailed account of the data we have collected.

[Back to the top](#numerical-analysis)


## Collaborative Discussion 2

**Discussion Topic**

**When dealing with statistical data, particularly for decision-making purposes, misinterpretations can be a serious issue.  For this collaborative discussion, read the Greenland et al. (2016) article from this week’s reading and reflect on these questions:  Under what situations should confidence intervals not be reported?  Why is a p-value not always enough to report?**

A lower than 0.05 (5%) p-value, as we have learned in this Module, enables us to reject the null hypothesis and assume that the test hypothesis is valid.  Conversely, a p-value higher than 0.05 (5%) lead us to the conclusion that the null hypothesis cannot be rejected and so the sample differences may be attributed to chance.   

In this regard, Ranstam (2012) argues that 'statistically insignificant outcome indicates nothing more than that the observed sample is too small to detect a population effect.  A statistically insignificant outcome should be interpreted as “absence of evidence, not evidence of absence”.  In other words, if a p-value is greater than the arbitrary cut-off of 5%, we lack evidence to assume that the test hypothesis is valid, but we cannot say with certainty that the null hypothesis is true.  According to Ranstam (2012), '[a] P-value provides only uncertainty information vis-a-vis a specific null hypothesis, no information on the statistical precision of an estimate.

'The smaller the P value, the more unusual the data would be if every single assumption were correct; but a very small P value does not tell us which assumption is incorrect'.  'Not only does a P value not tell us whether the hypothesis targeted for testing is true or not; it says nothing specifically related to that hypothesis unless we can be completely assured that every other assumption used for its computation is correct—an assurance that is lacking in far too many studies' (Greenland et al., 2016)

Sullivan & Feinn (2012) add another interesting dimension when dealing with and interpreting p-value and confidence intervals, that of the effect size.  'The effect size is the main finding of a quantitative study. While a P value can inform the reader whether an effect exists, the P value will not reveal the size of the effect.  In reporting and interpreting studies, both the substantive significance (effect size) and statistical significance (P value) are essential results to be reported. 

This means that it is not enough to only report the p-value as this could be misleading and not informative as for our research.


**Bibliography**

Greenland, S., Senn, SJ., Rothman, K. J., Carlin, B., Poole, C., Goodman, N., & Altman, G. (2016) Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology 31(4). 337–350. 

Ranstam, J. (2012) Why the P-value culture is bad and confidence intervals a better alternative. Osteoarthritis and Cartilage Volume 20, Issue 8. 805-808. https://doi.org/10.1016/j.joca.2012.04.001

Sullivan G.M., Feinn R. (2012) Using Effect Size—or Why the P Value Is Not Enough. Journal of Graduate Medical  Education Available on https://online225.psych.wisc.edu/wp-content/uploads/225-Master/225-UnitPages/Unit-07/Sullivan_JGME_2012.pdf [Accessed on 17 December 2024]

[Back to the top](#numerical-analysis)

## End of Module Assessment 1: Statistical Analysis Presentation

### Statistical Analysis Presentation

(https://docs.google.com/presentation/d/1F513wybGMd0HCvb8AYJnWsDeCPQlIaUyy_j7mMIyhv8/edit#slide=id.p1)


### Transcript of the presentation's audio file

(https://docs.google.com/document/d/1bojGT9jiYe9Fy5tF9vi-1ji2FDx8g8GJv7LNu3Nv1SY/edit?tab=t.0)


[Back to the top](#numerical-analysis)


## End of Module Assessment 2: Individual Reflection

**Assignment topic**

**This assessment focuses on your reflections on the skill and knowledge gained from the module. Please note that your reflections are not seen by other students, so you are free to discuss what is relevant to your learning and the processes you have gone through. Your reflection should address the following: Reflect in your data analysis skill and statistical knowledge and discuss how confident you are using R for statistical data analysis. Mention any challenges you faced.  Reflect upon your experience of interpreting statistical findings using p-value and confidence interval.  Also reflect upon on producing summary tables, contingency tables and producing plots using R.**

The Numerical Analysis module is part of the MSc programme, I am following at the University of Essex Online, in the field of Artificial Intelligence.   The aim of this module is for postgraduate students to: ‘a) develop a systematic understanding of foundational mathematical principles and methods, b) facilitate their ability to interpret the results generated when using data science and AI tools, c) critically evaluate the use of statistical analysis and the numeric interpretation of results as aids in the decision-making process and d) critically appraise and present results of a statistical analysis to a diverse audience’ (UoEO Module Home, n.d.).  A prominent role in achieving these objectives plays the familiarisation of the postgraduate student with the RStudio, which makes statistical data analysis and representation of analysis results (plots, graphs) of large datasets much easier and faster.

For this individual reflection, I will make use of mainly two reflective models: 
a) ‘What? So What? Now what?’ (experience, implication of the situation and action plan) (Driscol, 1994 and Rolfe et al., 2001) and 
b) the Gibbs’ reflective Cycle (description, feelings, evaluation, analysis, conclusion, action plan) (UoEO Short Guide to Reflective Writing, n.d. and The University of Edinburgh Reflection Toolkit, n.d.).  

According to the structure of the module, mathematical concepts and foundations of statistical data analysis were first presented on the learning platform either via lecturecasts, unit notes, or reading lists.  Further, we were tasked to perform RStudio commands to get a certain given result (by following the recommended material instructions).  Then, we were supposed to perform several formative tasks and data activities, to familiarise ourselves with the software and learn how to formulate commands (coding process) and get data analysis results by ‘trial and error’.
Given that I do not come from a STEM background myself, having to deal with mathematical concepts and statistical foundations was quite overwhelming for me, not to say a daunting task.  However, I was aware that some basic concepts of statistical analysis would be very helpful for me to advance with the following modules in the Artificial Intelligence programme.  What I have learned in this module, I believe will largely help me interpret statistical analysis results (assessing the p-value, the Confidence Interval (CI), the correlation co-efficient etc), be critical about the robustness of the findings and evaluate the usefulness of the statistical results as aids to decision-making process.

I enjoyed the first introductory units of the module very much, where basic mathematical and statistical concepts were effectively explained such as mean/median, minimum/maximum/range, variance/standard deviation, the difference between descriptive and inferential statistics etc.  In this effort of mine, my principal ally was the unit notes, the recommended reading lists, the seminar sessions and the activities we were asked to perform later.  The pace of the learning was normal, at least in the first half of the module, but it acquired much greater difficulty towards the end.  

In the last units, it has to be borne in mind that the lecturecasts were very difficult to understand, as they were intended for a more expert audience or at least to those who were already knowledgeable.  This is why I got to watch them again and again and, in particular, after having read the recommended bibliography, watched YouTube videos and visited informative websites on statistics and RStudio (Annex).   I was quite determined to get a grasp of all items to be covered in the module, so I made use of every available reliable source apart from the module material (Annex).  I also exchanged a series of emails with my tutor who kindly gave me feedback on the commands I had performed on RStudio and some hints when I needed some extra help.  
Another formative activity that also contributed to my learning process was engaging in a discussion with my peers (Collaborative discussions 1 & 2). Even though, due to the non-mandatory nature of the activity, not all peers contributed to the discussion, I exchanged valuable opinions with those who participated.  Having to draft a post and respond to the comments of the peers, made me read other material than that offered in the module, from the University of Essex online library and the Google Scholar.  Writing a post in a collaborative discussion forum may be work-intensive, as each postgraduate student is keen to share an impactful contribution, which will generate interest (Annex).

Nevertheless, the trickiest part for my learning process was performing commands and getting statistical results on RStudio.  This seemed to me quite frustrating at some point, as the absence of a bracket ‘()’ or the superfluous addition of a character made the software giving an ‘error’.  In many cases, it was not clear to me where the error was lying.  This is why I had to repeat many times the commands, making sure that all components were included, ask guidance from my tutor, and seek help from reliable YouTube videos and websites.  After having completed the module, I now feel much more confident with at least the basic commands of the software such as performing basic arithmetic, converting variables, and managing missing variables, developing graphs and plots, creating sub samples, performing statistical analysis using a null or alternative hypothesis, taking a decision based on p-value and statistical significance and running normality tests, correlations tests, and regression analysis.

Familiarising myself with RStudio and statistical analysis made me realise how important it is to be able to understand if the result I get is statistically significant, if I can reject the null hypothesis and accept the alternative one (when the p-value is lower than 0.05), how to interpret the Confidence Interval etc  This will help me get an insight into whether the statistical analysis I read is reliable or not, so I can make an evidence-informed decision.  I am sure that the valuable knowledge gained in this module will help me understand better how the Artificial Intelligence is working as well as its potential and opportunities but also its risks and implications in our lives.

To conclude, I got to understand how important it is to learn by experience and by ‘trial and error’, especially when having to learn mathematical and statistical analysis concepts and perform RStudio commands.  While the feeling of frustration when you do not get the desired result or when you find it difficult to grasp a certain concept is overwhelming, on the other hand, it is equally rewarding when you are patient, read very carefully the material, ask the tutor for guidance, follow the seminar sessions, watch YouTube videos, seek other reliable sources and finally when you deepen your knowledge and reach the desired objective.
 
**List of References**

Driscoll J. (1994). Reflective practice for practise. Senior Nurse, 13, 47 -50

Rolfe, G., Freshwater, D. & Jasper, M. (2001) Critical reflection in nursing and the helping professions: a user’s guide. Basingstoke: Palgrave Macmillan 

The University of Edinburgh (n.d.). Reflection Toolkit. Available from https://reflection.ed.ac.uk/reflectors-toolkit/reflecting-on-experience [Accessed on 9 January 2025]

UoEO (n.d.). Numerical Analysis October 2024, Module Home Available from https://www.my-course.co.uk/course/view.php?id=12569&section=0 [Accessed on 12 January 2025]

UoEO (n.d.).  Short Guide to Reflective Writing. Available from A short guide to reflective writing.pdf [Accessed on 9 January]

UoEO (n.d.).  Study Skills Hub. Reflective Writing Video. Available from https://www.my-course.co.uk/course/view.php?id=13&section=9#reflectivewriting [Accessed on 6 January]

[Back to the top](#numerical-analysis)

[Go to main Menu](https://narchondas.github.io/)
