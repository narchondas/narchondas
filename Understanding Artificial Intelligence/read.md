# Understanding Artificial Intelligence

![image](https://github.com/user-attachments/assets/ac9ffe4c-dd30-4876-9e37-a0abd7aa42bb)


Use the following links to navigate to the start of the sections

[1. Collaborative Discussion 1](#collaborative-discussion-1)

[2. Collaborative Discussion 2](#collaborative-discussion-2)

[3. Individual Essay: Artificial Intelligence and its Applications](#individual-essay-artificial-intelligence-and-its-applications)

[4. Artificial Intelligence (AI) Solution Implementation](#artificial-intelligence-ai-solution-implementation)


## Learning outcomes

### In this module, I shall:

* Develop an understanding of the history and future of Artificial Intelligence. To include definition of AI, professional and ethical issues, as well as key application areas (Industry 4.0 and FinTech).

* Develop an understanding of AI fundamentals including the Alan Turing Test, knowledge representation and approaches to developing learning systems.

* Examine programming paradigms and algorithms for Machine Learning.

* Examine the preparation data for AI solutions.

* Develop programming abilities for learning algorithm implementation.

### On completion of this module, I will be able to:

* Understand the legal, ethical and professional issues brought up by AI and the impact of AI on society.

* Understand and critically analyse the essential concepts, principles, methods, techniques and problems of AI.

* Demonstrate a critical understanding of data requirements and programming paradigms applicable to AI.

* Apply and evaluate critically the various methods, tools and technologies applied to an AI project in order to develop an effective plan and delivery of solutions to a business problem.


## Collaborative Discussion 1

### Initial & summary posts

**Discussion Topic**

**Discuss why Artificial Intelligence is now ubiquitous and why it is important for companies to invest in Artificial Intelligence technologies.
Your discussion could consider/identify:  A typical company or industry that employs AI technologies, as well as the nature of the business to set the context for the discussion.
The economic benefits to the company or industry, and other implications of using Artificial Intelligence (AI) technology.  You should demonstrate that you understand the topic covered and ensure you use references to academic literature (journals, books, reports, etc.). This is activity will provide evidence of your personal growth.**

**Initial Post**

The customer recommendation system by Amazon, the world-leader retail online store, makes extensive use of AI-enabled tools to improve customer experience and satisfaction with a view to ultimately increasing the orders placed by users and the business revenues.  Amazon recommendations are based on the products purchased by the user in the past on the same site, their visits to the Amazon product web pages as well as to those purchased by other customers with similar interests.    

The company even makes a step further by combining related products and offering a new more upgraded order option to the user.  The product combination is accompanied with a new price tag, so customers are indirectly pushed to buy both items based on data of preferences from customers with similar interests.  Amazon recommendation system has been made possible thanks to the possibility of analysing 'big data' real-time, originating from the order history and preferences of Amazon customers around the world.  According to S. Yin and O. Kaynak (2015), 'big data refers to data sets whose size is beyond the ability of typical database software tools to capture, store, manage, and analyze', whereas the same authors argue that the customer-centric experience will primarily dominate the AI-enabled tools environment.

'The remarkable advances in computing power and the creation of the World Wide Web have facilitated the creation of very large data sets' (Russel, Stuart et al., 2021), which have subsequently contributed to the customisation of consumer order proposals.

To what extent do you believe that the protection of the personal data of customers is infringed when Amazon is collecting their preferences and making recommendations to them? To what extent do you believe that the use of AI-enabled tools for recommendations is nudging customers to buy more and more products from the same company, leading to disloyal competition practices?

**References**

Russell, Stuart, and Peter Norvig. Artificial Intelligence: a Modern Approach, Global Edition, Pearson Education, Limited, 2021. ProQuest Ebook Central.  Availble from http://ebookcentral.proquest.com/lib/universityofessex-ebooks/detail.action?docID=6563568 [Accessed on 1 August 2024]

S. Yin and O. Kaynak, "Big Data for Modern Industry: Challenges and Trends [Point of View]," in Proceedings of the IEEE, vol. 103, no. 2, pp. 143-146, Feb. 2015.  Available from https://ieeexplore.ieee.org/document/7067026 [Accessed on 2 August 2024]


**Summary**

The customer recommendation system by Amazon makes extensive use of AI-enabled tools to improve customer experience with a view to ultimately increasing orders placed by users and business revenues.  Amazon recommendations are based on the products purchased by the user in the past on the same site, their visits to the Amazon product web pages as well as to those purchased by other customers with similar interests.    

The company even makes a step further by offering a combination of products, accompanied with a new price tag, so customers are indirectly pushed to buy more items.  Amazon recommendation system has been made possible thanks to the possibility of analysing 'big data' real-time, originating from the order history and preferences of Amazon customers around the world.  This is line with what S. Yin and O. Kaynak (2015) have argued, namely that the customer-centric experience will primarily dominate the AI environment.

Peers reacting to the post have expressed their concern primarily when it comes to the question of clarity/transparency of how customer data are being used and also to the frustration that such recommendation system may generate if perceived by online customers as too intrusive and (Moore et al., 2015) ‘creepy’. 

It turns out that these companies have much more leverage than their customers concerning data collection and AI utilization.  This is why it is crucial that a legal/regulatory framework be adopted by governments. The EU AI Act (2024), one of the first attempts of a world regulator to put some boundaries and limits to the uncontrolled use of AI, seems to strike the right balance between innovation and safety/ethics. It allows researchers to experiment with AI tools in lab conditions, while at the same time prohibiting AI use representing an unacceptable risk.   It seems plausible that apart from the EU, other big regulators will follow suit and adopt similar measures, if they wish to continue trading with the EU Single market (the so called 'Brussels effect').

**References**

European Commission (2023) EU Artificial Intelligence Act, Available at https://artificialintelligenceact.eu/the-act/

Moore, R.S., Moore, M.L. and Shanahan, K.J., 2015. Creepy marketing: Three dimensions of perceived excessive online privacy violation. Marketing, pp.1-10.

S. Yin and O. Kaynak, "Big Data for Modern Industry: Challenges and Trends [Point of View]," in Proceedings of the IEEE, vol. 103, no. 2, pp. 143-146, Feb. 2015.  Available from https://ieeexplore.ieee.org/document/7067026 [Accessed on 2 August 2024]


### Response to my peers' posts

Hello Abdullah,

thanks for sharing your post on Facebook and on the use of AI to eliminate fake news.  In this response of mine, I would like to further comment on the AI use as for the targeted advertisement, as I believe the issue raises a lot of questions related to ethics, privacy and data protection, but also it is of paramount importance for business efficiency and revenue increase.  

According to Facebook Business (2020), the company makes use of two key elements when it comes to advertisement namely the consumer/user group selected by advertisers and the rating of their advertisement auction system.  The aim is to show the right advertisement for the right Facebook user, thus enhancing the personalised user experience.

Meta (Facebook) has recently taken a step further and is intending to allow advertisers 'to automate the creation of multiple versions of adverts featuring different text and images aimed at different audiences'.  Businesses wishing to advertise the same product or service via the platform will be able to differentiate the advertisement content and the way this advertisement is shown to the Facebook user (language, colours, message etc) in an automated way (using AI-enabled tools), depending on their demographic, geographical etc characteristics (Marr, 2023).

While it seems a tautology that targeted advertisement could boost business earnings, on the other hand, one could also argue that this 'extremely' targeted advertisement might have some unexpected and unintended repercussions on the user experience if this is perceived as too invasive.  This could at best lead to dissatisfaction or disconcert of technologically minded users, who might be extremely worried about their privacy and data protection.


**References**

Facebook (2020, 11 June) Good questions, real answers: How does Facebook use machine learning to deliver ads? Facebook Business. Available from https://www.facebook.com/business/news/good-questions-real-answers-how-does-facebook-use-machine-learning-to-deliver-ads [Accessed 8 August 2024]

Marr, B. (2023, 2 May) 5 Amazing ways Meta (Facebook) is using Generative AI. Forbes. Available from https://www.forbes.com/sites/bernardmarr/2023/05/02/5-amazing-ways-how-meta-facebook-is-using-generative-ai/ [Accessed 8 August 2024]


Dear Abdulaziz,

you raise a number of interesting points regarding the relation between Artificial Intelligence and e-commerce and to what extent companies can take advantage of the AI-enabled tools to optimise process, demand and customer experience, among others.

I totally agree with your takeaways and I could kindly draw your attention to the four ways AI is transforming e-commerce, as Nick Heethuis puts it (Forbes, 16 February 2022). These are AI copyrighting, chatbots and virtual assistants (as you have already mentioned), personalisation of the customer experience and inventory management (you have also mentioned).

E-commerce companies by means of AI-enabled tools can:

1. gain analytical insights into what the consumers are interested in at a particular moment, what their tastes and preferences are, what price they are willing to pay

2. create a personalised customer experience, making smart and timely recommendations, offering a combination of related products (Amazon) before checking out

3. enhance their competitiveness by adjusting demand and storage capacity.

As we have learned, S. Yin and O. Kaynak (2015) argue that the customer-centric experience will primarily dominate the AI-enabled tools environment, whereas Mike Loukides (2021) stresses that the retail sector' maturity as for the AI in 2021 was quite high at 40%. This is at least very promising when it comes to the AI design, implementation and deployment in the e-commerce/retail sector. One might expect that this positive upward trend is going to be strengthened in the immediate future.

**References**

Heethuis N. (16 February, 2022) Intelligence Is Transforming E-Commerce. Forbes. Available from: https://www.forbes.com/sites/theyec/2022/02/15/four-ways-artificial-intelligence-is-transforming-e-commerce/ [Accessed 6 August 2024]

Yin S. and Kaynak O., "Big Data for Modern Industry: Challenges and Trends [Point of View]," in Proceedings of the IEEE, vol. 103, no. 2, pp. 143-146, Feb. 2015. Available from https://ieeexplore.ieee.org/document/7067026 [Accessed 6 August 2024]

Loukides M. (21 April, 2021) AI Adoption in the Enterprise 2021. O'Reilly. Available from https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/ [Accessed 6 August 2024]

[Back to the top](#understanding-artificial-intelligence)

## Collaborative Discussion 2

### Initial & summary posts

**Discussion Topic**

**Identify and discuss two machine learning algorithms and the context in which they can be employed. Your discussion could consider:  Supervised and/or unsupervised learning algorithms. For example, if considering supervised learning, what type of learning algorithms would be ideal for the solution?  The strengths and weaknesses of this approach to learning.
You should demonstrate that you understand the topic covered and ensure you use references to academic literature (journals, books, reports, etc.). This is activity will provide evidence of your personal growth.**

**Initial Post**

‘A decision tree is a […] supervised learning algorithm, which is utilised for both classification and regression tasks’ (IBM). It consists of a root, internal nodes and leaves.  ‘The internal nodes of the tree represent a test on an attribute or subset of attributes’ (Cohen, 2021).  Decision trees (DTs) measure ‘the difference of entropy before and after a split’ (information gain).  ‘The node with the highest gain becomes the root node’ (Bell, 2020).  DTs can easily classify data and predict the outcome based on the training data, so they are widely used, among others, for data mining, in bank/finance services to check the trustworthiness of clients, in customer service, where they direct phones calls/emails to the appropriate department (sales, after-sales services, repair/feedback, payment methods)

DTs are simple to understand and interpret as they can be visualised, can process both numerical and categorical data, support a certain degree of explainability contratry to the ‘black box’ of artificial neural network and they require little to no data preparation (Learn Scikit).  Nonetheless, DTs can become overly complex as they cannot generalise well to new data (overfitting) and even slight variations can deliver a different outcome (IBM).

A support vector machine (SVM) is another supervised learning approach for classifying objects/images.  ‘Classification problems aim to predict the category (class) to which a given input belongs’.  SVM algorithm identifies the optimal hyperplane among an infinite set because it assesses some data more critical than others for finding the best diving line/hyperplane: the support vectors (Prinzi et al., 2024).  SVM are used in the analysis of radiological images (breast cancer detection, cardiac disease diagnosis etc) as well as for identifying fraudulent credit card activity, recognising handwritten digits and letters etc

A very good feature of SVM is that only a small training set is needed to provide very good results (Tzotsos et al., 2008), so they can generalise quite well to new data (avoiding overfitting). SVM are also effective in high-dimensional spaces and efficient in memory usage as they only need to store a small fraction of the training data. However, SVM can be also computationally intensive.  The number of possible kernels/transformations is infinite and can make it hard to choose the right one. 

**References**

Cohen S. MD (2021) The basics of machine learning: strategies and techniques in Artificial Intelligence and Deep Learning in Pathology. Available from https://www.sciencedirect.com/topics/computer-science/decision-tree-algorithm [Accessed on 3 September 2024]

Bell, J. (2020) Machine Learning: Hands-On for Developers and Technical Professionals. 2nd ed. Chichester: Wiley

European Information Technologies Certification Academy (7 August, 2023) What are some advantages of using support vector machines (SVMs) in machine learning applications? Available from https://eitca.org/artificial-intelligence/eitc-ai-mlp-machine-learning-with-python/support-vector-machine/support-vector-machine-introduction-and-application/examination-review-support-vector-machine-introduction-and-application/what-are-some-advantages-of-using-support-vector-machines-svms-in-machine-learning-applications/ [Accessed on 3 September]

IBM, What is a decision tree? Available from https://www.ibm.com/topics/decision-trees [Accessed on 4 September 2024]

Learn Scikit Available from https://scikit-learn.org/stable/modules/tree.html [Accessed on 4 September 2024]

Prinzi, F., Currieri, T., Gaglio, S. et al. (2024) Shallow and deep learning classifiers in medical image analysis. Eur Radiol Exp 8, 26. https://doi.org/10.1186/s41747-024-00428-2

Tzotsos, Angelos & Argialas, Demetre (2008) Support Vector Machine Classification for Object-Based Image Analysis.  Available from https://www.researchgate.net/publication/225929583_Support_Vector_Machine_Classification_for_Object-Based_Image_Analysis [Accessed on 4 September]


**Summary**

‘A decision tree, a […] supervised learning algorithm, is utilised for both classification and regression tasks’ (IBM, ND). Decision trees (DTs) measure ‘the difference of entropy before and after a split’ (information gain).  ‘The node with the highest gain becomes the root node’ (Bell, 2020).  DTs can easily classify data and predict the outcome based on the training data, so they are widely used for data mining, in banking/finance, customer service.  They are simple to understand as they can be visualised, can process both numerical and categorical data, support a certain degree of explainability contrary to the ‘black box’ of artificial neural network and they require little to no data preparation (Learn Scikit, ND).  

Nonetheless, DTs can become overly complex as they work well with training data but not when applying new or unseen real-world data (overfitting) (Wang et al., 2010).  One way to avoid this is by pre-pruning and post-pruning, which help reduce overfitting (Bramer, 2007) and improve the accuracy of the overall classification, when applied to the validation dataset (Song, 2015).

Support vector machines (SVMs), another supervised learning approach for classifying objects/images, identify the optimal hyperplane among an infinite set because they assess some data more critical than others for finding the best diving line/hyperplane: the support vectors (Prinzi et al., 2024).  SVMs are highly effective in handling high-dimensional data, which is invaluable in fields like text classification and bioinformatics (Ben-Hur & Weston, 2010), classification of complex patterns in medical images (Litjens et al., 2017).  A very good feature of SVMs is that only a small training set is needed to provide very good results (Tzotsos et al., 2008), so they can generalise quite well to new data.  

However, SVMs can be also computationally intensive, sensitive to parameter tuning, they have difficulty in interpreting complex models and also, they can face scalability issues when applied to extremely large data sets.  Training an SVM on millions of samples can become impractical due to memory and computational constraints (Tabsharani F.)

**Reference list**

Bell, J. (2020) Machine Learning: Hands-On for Developers and Technical Professionals. 2nd ed. Chichester: Wiley

Ben-Hur, A. & Weston, J. (2010). A user’s guide to support vector machines. Methods in Molecular Biology, 609, 223-239.

Bramer, M., (2007). Avoiding overfitting of decision trees. Principles of data mining, pp.119-134.

IBM, (ND) What is a decision tree? Available from https://www.ibm.com/topics/decision-trees [Accessed on 4 September 2024]

Learn Scikit, (ND) Available from https://scikit-learn.org/stable/modules/tree.html [Accessed on 4 September 2024]

Litjens, G. et al. (2017). A survey on deep learning in medical image analysis. Medical Image Analysis, 42, 60-88.

Prinzi, F., Currieri, T., Gaglio, S. et al. (2024) Shallow and deep learning classifiers in medical image analysis. Eur Radiol Exp 8, 26. https://doi.org/10.1186/s41747-024-00428-2

Song YY, Lu Y. (25 April 2015), Decision tree methods: applications for classification and prediction. Shanghai Arch Psychiatry. 27(2):130-5. DOI: 10.11919/j.issn.1002-0829.215044

Tabsharani F. (ND), Support vector machine (SVM). Available from https://www.techtarget.com/whatis/definition/support-vector-machine-SVM#:~:text=A%20support%20vector%20machine%20(SVM)%20is%20a%20type%20of%20supervised,data%20set%20into%20two%20groups [Accessed on 9 September]

Tzotsos, Angelos & Argialas, Demetre (2008) Support Vector Machine Classification for Object-Based Image Analysis.  Available from https://www.researchgate.net/publication/225929583_Support_Vector_Machine_Classification_for_Object-Based_Image_Analysis [Accessed on 4 September]

Wang, T., Qin, Z., Jin, Z. and Zhang, S., 2010. Handling over-fitting in test cost-sensitive decision tree learning by feature selection, smoothing and pruning. Journal of Systems and Software, 83(7), pp.1137-1147.

### Response to my peers' posts

Dear Elias, 

thanks for your thoughts on supervised/unsupervised learning algorithms.  On my side, I would like to discuss much further the K-means algorithm.

K-means clustering, as you say, is an unsupervised machine learning algorithm used for clustering or grouping similar data points together in a dataset.  It constitutes a partitioning algorithm that divides the data into non-overlapping clusters, where each data point belongs to a single cluster (Nishan, 2023).  In other words, ‘the k-means algorithm is aimed at partitioning objects or points to be analysed into well-separated clusters’.  There is no optimal k-means algorithm, as it primarily depends on the characteristics of the data set, the size and the number of variables in the instances (Oti et al, 2021).

When it comes to K-means algorithm, the treatment of outliers merits some consideration.  Even though outlier detection has mostly to do with the domain knowledge and expertise in the feature engineering, an outlier is identified when the distance to the closest centroid seems significant.  The k-means algorithm is said to more easily identify sparseness of data points from isolation.  Points in sparse areas are not outliers, while isolated points are (Duboue, 2020). 

The cluster analysis is a data mining tool that is increasingly used nowadays in large and multidimensional databases.  As you mention in your post, retail industry (online shops) are heavily investing in analysing customer preference, needs and buying behaviour through clustering ML techniques.  Apart from the retail industry, such technique is used in a lot of fields such as statistics, medicine, patterns identification etc (Suyal, 2024)

**References**

Duboue, P. (2020) The Art of Feature Engineering: Essentials for Machine Learning. Cambridge: Cambridge University Press

Nishan, J. (26 May 2023) Mastering data clustering: Your comprehensive guide to K-means and K-means++, AI Accelerator Institute. Available from https://www.aiacceleratorinstitute.com/mastering-data-clustering-your-comprehensive-guide-to-k-means-and-k-means/ [Accessed on 9 September 2024)

Oti, E. et al (2021). Comprehensive Review of K-Means Clustering Algorithms. International Journal of Advances in Scientific Research and Engineering. Available from https://www.researchgate.net/publication/354547481_Comprehensive_Review_of_K-Means_Clustering_Algorithms [Accessed on 9 September 2024]

Suyal, M. & Sharma, S. (2024) A Review on Analysis of K-Means Clustering Machine Learning Algorithm based on Unsupervised Learning. Journal of Artificial Intelligence and Systems. Available from https://www.researchgate.net/publication/379878557_A_Review_on_Analysis_of_K-Means_Clustering_Machine_Learning_Algorithm_based_on_Unsupervised_Learning [Accessed on 8 September]

Dear Jaco,

in my peer response, I would like to add to the discussion on the decision trees and more specifically in the pruning process.

As you argue, a decision tree (DTs) is a supervised machine learning model, which makes use of labelled input and datasets for output to train a model.

The way DTs are structured enable us to easily understand the rationale of a decision and to ‘explain’ (justify) the decision-making process.  There are a lot of advantages, for instance, DTs do not require data preprocessing, they can work with versatile data, and they are good at detecting outliers.  Nevertheless, one may end up with very large DTs, which cannot generalise (overfitting).  A minor variation may give a totally different result, whereas attention should be paid when interpreting decision tree models and when using the results of these models to develop causal hypotheses (Aswini, ND) (Song, 2015).

DTs can be used in a variety of fields from a recommendation engine (taking the decisions made by consumers over time and creating nodes based on those decisions) (Anon), to medical decisions and diagnoses.

I would like to say a few words about one of the methods to remove overfitting: pruning.

A way to build a decision tree model is to grow a large tree first, and then prune it to optimal size by removing nodes that provide less additional information.  There are two types of pruning, pre-pruning (forward pruning) and post-pruning (backward pruning).

Pre-pruning prevents the generation of non-significant branches, while post-pruning is used after generating a full decision tree to remove branches aiming to improve the accuracy of the overall classification when applied to the validation dataset (Song, 2015).


**References**

Aswini R., (ND) Why Do We Use Decision Trees in Machine Learning? Available from: https://www.turing.com/kb/importance-of-decision-trees-in-machine-learning [Accessed on 10 September 2024]

Anon, (ND), Decision Tree. Available from: https://www.mastersindatascience.org/learning/machine-learning-algorithms/decision-tree/ [Accessed on 10 September 2024]

Song YY, Lu Y. (25 April 2015), Decision tree methods: applications for classification and prediction. Shanghai Arch Psychiatry. 27(2):130-5. DOI: 10.11919/j.issn.1002-0829.215


[Back to the top](#understanding-artificial-intelligence)


## Individual Essay: Artificial Intelligence and its Applications

**Assignment Details**

**A local start-up finance company is vaguely aware of AI and the potential benefits, as well as the harms that these technologies can cause to society. This has caused the Senior Management of the company to have some reservations about AI. As an Artificial Intelligence consultant, you are to present a report to persuade the management of the company to accept your idea to employ AI technologies to improve business processes for competitiveness.  Your report should identify three key areas to which the company could apply AI technologies to facilitate its operations and increase their return on investment. The report should also consider data needed, as well as the sort of approach that will be required to develop an AI system.**

**How to tap into the AI potential and further boost our competitiveness** 

As a finance company, we grant loans to individuals and businesses (personal and corporate branch), including merchants, retailers and manufacturers for the purchase of goods and services with securities (Britannica, ND).  To further enhance our competitiveness prospects and maintain our market share in a challenging and unpredictable financial framework, there is a pressing need our company endorse a series of Artificial Intelligence (AI) enabled tools. These AI-enabled tools will aim to i) facilitate current internal business/customer operations, ii) automatically process credit risk of customers and iii) target creditworthy clients by personalising investment opportunities based on their profile.  
This report explores the phasing-in of some AI-enabled tools in our company, the expected benefits (turnover increase and market position improvement) as well as the pitfalls and potential risks we have to take into account.   

My department has made use of the NAFTA framework before making the business case for staged AI adoption.  First, we identified the problem (Need), explored to what extent the AI-solution is aligned with the company’s broader strategy (Alignment), and determined its financial viability (Finance) (off-the-shelf, open source and bespoke), and thus guarantee return on investment.   Subsequently, we duly tested the need for AI implementation and how to best integrate it in the corporate operations (Test) and then we identified the tools, which will enable us to assess the risks involved in the technology (Analyse) (Mcilrath, B. & Kotnour. T, 2002; Terence Tse et al., 2021; Poree, J., 2022; University of Oxford, 2023).

i) The first key area of AI deployment could be the customer service.  We propose the extensive use of automated voice assistants answering customers’ simple questions and directing the complex ones to the appropriate department as well as the introduction of chatbots (computer programs that use artificial intelligence to imitate a conversation with a human-Bowman, 2024) for customer web/mobile application services.  Both tools will leverage natural language processing (NLP) i.e. speech and speech-to-text recognition, using supervised learning algorithms in particular Decision Trees (DTs)- (the technological characteristics of the envisaged algorithmic models and the trade-offs will be discussed further below).  By answering questions and completing routine tasks 24/7 (IBM, ND), the AI-solution will enable us to reorientate human resources to more strategic-wise departments as the customers’ questions will be automatically answered, whereas the more complex ones will be directed to the responsible department (follow-up on pending loan applications, complaints etc).  That way, we will optimise the customer experience and make sure we deal with the most critical ones.   Nonetheless, some customers may feel frustrated by this automated way of dealing with inquiries as the AI-solution may not be able to understand the question upfront and it may direct the phone call to the wrong department, which may result in us losing potential good customers. Or else, the chatbots’ answers may be the result of hallucination (generating false information and presenting it in a convincing way).

ii) The second area of AI deployment could be credit risk analysis, scoring and loan approval.  In this case also, supervised learning algorithms (DTs) can also be used.  They will automatically evaluate the creditworthiness of potential customers based on their economic behaviour, financial data, credit history, potential cases of default using data extracted from centralised databases of the intra-banking system as well as on the income data from tax authorities, following the explicit consent of the candidate customers (individual/corporate).  Such algorithms will thus help our company with risk assessment, credit scoring and document verification and ultimately, they will help us speeding up the loan approval procedures.  However, the financing approval will be only complemented by automated AI tools, as human intervention will be necessary for the final decision (Bowman, 2024; PEX, 2024; Deloitte, ND; IBM, ND).  Given that ‘AI algorithms can analyse vast amounts of data to identify patterns and assess creditworthiness more accurately, […] this can lead to fewer loan defaults, reduced risk provisions, and improved profit margins, […] [This can] improve risk management leading to substantial cost savings through improved fraud detection and creditworthiness assessments’ (Chlouverakis, 2024).  
On the other hand, such processing of sensitive financial data may result in ‘false positives’ and ‘false negatives’ due to algorithmic bias, data misuse, data privacy and security infringements.  For example, the algorithm may reject people from a given social, ethnic, social background (bias), offer a higher interest rate for the loan applicant or ask for a higher value security in comparison to other potential customers of the same creditworthiness level.

iii) The third area of AI deployment could be the provision of proactive personalised financing services to customers by means of recommendations (investment advice/financing offers), based on customer journeys, peer interactions, risk preferences, and financial goals (Cloud.google, ND) as well as ‘customers' transaction history [and] spending habits […]. Through such personalisation, institutions can improve customer satisfaction and loyalty’ (Onestream, ND; IBM, ND).  In this case, an envisaged AI-solution could be an unsupervised learning algorithm (K-means), which would cluster potential customers with similar financial goals and income levels based on unlabelled data.  That way, we could be able to make personalised financial services recommendations in a proactive way, increasing our earnings and market share.  On the downside, such solution may pose some explainability challenges, as its inherent complexity and opacity complicate the understanding of their decision-making processes (Chlouverakis, 2024).  In addition, serious data privacy and safety issues may equally be raised with similar AI algorithms.
As mentioned above, to facilitate current internal business and customer operations, and automatically analyse the credit risk of loan applicants (individual/corporate), we propose to make use of the Decision Tree (DT) algorithmic model.   A decision tree is a supervised machine learning model, which makes use of labelled input and datasets for output to train a model.   It consists of a root, internal nodes and leaves.  ‘The internal nodes of the tree represent a test on an attribute or subset of attributes’ (Cohen, 2021).   DTs can easily classify data and predict the outcome based on the training data, so they are widely used for data mining, in bank/finance services to check the trustworthiness of clients, in customer service, where they direct phones calls/emails to the appropriate department (sales, after-sales services, repair/feedback, payment methods).  Therefore, this model is suitable for us to deploy in the customer service department and in the credit risk analysis department.

It has to be borne in mind, though, that all techniques and algorithms have their own particular strengths and weaknesses.   On the one hand, DTs are simple to understand and interpret as they can be visualised, can process both numerical and categorical data, support a certain degree of explainability contrary to the ‘black box’ of artificial neural network and they require little to no data preparation (Learn Scikit, ND).   

On the other hand, DTs can become overly complex as they cannot generalise well to new data (overfitting) and even slight variations can deliver a different outcome (IBM, ND).   This is the reason why DTs are considered as unstable, in the sense that once an attribute value is modified, the result may be also modified, giving another outcome.  In our company, this may lead to ‘false negatives’ or ‘false positives’.  The repercussions could be: not convincingly answering the clients’ requests on the phone/web page (chatbox), forwarding a complaint to the wrong department, failing to identify the customer, which may lead to their frustration.  As for the credit risk analysis, the DT may give the wrong outcome as for the creditworthiness of a loan applicant.  Nevertheless, given that the final decision of the loan application will not entirely rely on the algorithm, but it will need human intervention, the repercussions of this disadvantage are deemed to be very limited.  

As for the difficulty of this model to generalise well to new data, two of the methods to address this disadvantage are pre-pruning (preventing the generation of non-significant branches) or post-pruning (removing branches after generating a full decision tree) (Song, 2015).

Regarding the targeting of creditworthy clients by personalising investment opportunities based on their profile, we envisage using the most common unsupervised learning model, which is clustering (detecting potentially useful clusters of input examples) and particularly the centroid model (k-means).  According to this model, ‘[e]ach one of the clusters has a centroid […], a point where the distance of the objects will be calculated.  The clusters are defined by an iterative process on the distances of the objects to calculate which are nearest to the centroid.  In unsupervised learning, the agent learns patterns in the input without any explicit feedback’ (Russel et al., 2021).

Retail industry is heavily investing in analysing customer preferences, needs and buying behaviour through clustering techniques.   Such technique is also used in a lot of fields such as statistics, medicine, patterns identification etc (Suyal, 2024).  ‘Social media network analysis uses clustering to determine communities of users.  With so many users on Facebook, […], using these sorts of techniques can refine advertising so that certain ads go to specific groups of customers’ (Bell, 2020).   In addition, website logs and search results are often clustered to show more relevant search result groups, whereas clustering is also used to refine search engine queries (Bell, 2020).

Through this model, we can group customers with similar income/creditworthiness ratings into clusters and proactively offer them personalised investment and financing advice/recommendations.  Potential mismatches of clusters and customers could be alleviated, as in that case also human intervention will be determining.

Following the aforementioned analysis, our finance company could start deploying the envisaged AI-solutions as a pilot.  Then, we will collect experience/data from the customers and staff alike, proceed to the assessment of the economic results achieved and then potentially deploy the AI-solutions at a larger scale.  Some subsequent areas of potential AI deployment could be fraud detection and prevention, cash flow forecasting, automated reporting, regulatory compliance, investment management, invoice processing and predictive analytics.

**Reference list**

Britannica, (ND) Available from  https://www.britannica.com/money/finance-company [Accessed on 20 September 2024]

Bell, J. (2020) Machine Learning: Hands-On for Developers and Technical Professionals. 2nd ed. Chichester: Wiley. Available from https://learning.oreilly.com/library/view/machine-learning-2nd/9781119642145/?sso_link=yes&sso_link_from=university-of-essex [Accessed on 15 September 2024]

Bowman J. (20 August, 2024) How Artificial Intelligence is Used in Finance Learn how AI is transforming the financial sector Available from https://www.fool.com/investing/stock-market/market-sectors/information-technology/ai-stocks/ai-in-finance/#:~:text=AI%20is%20being%20used%20in,insurance%2C%20and%20even%20customer%20service [Accessed on 15 September 2024]

Chlouverakis K. (26 April, 2024) How artificial intelligence is reshaping the financial services industry Available from https://www.ey.com/en_gr/financial-services/how-artificial-intelligence-is-reshaping-the-financial-services-industry [Accessed on 10 September 2024]

Cloud. Google (ND), Available from https://cloud.google.com/discover/finance-ai 

Cohen S. MD (2021) Chapter 2: The basics of machine learning: strategies and techniques, Artificial Intelligence and Deep Learning in Pathology. Available from 
https://www.sciencedirect.com/topics/computer-science/decision-tree-algorithm [Accessed on 3 September 2024]

Crumley B., (20 June, 2024), Finance Jobs Will Be Changed the Most by AI, Report Says, Available from https://www.inc.com/bruce-crumley/finance-jobs-will-be-changed-most-by-ai-report-says.html [Accessed on 19 September 2024]

Deloitte (ND), How Artificial Intelligence is Transforming the Financial Services Industry Available from https://www.deloitte.com/ng/en/services/risk-advisory/services/how-artificial-intelligence-is-transforming-the-financial-services-industry.html [Accessed on 18 September 2024]

Duboue, P. (2020) The Art of Feature Engineering: Essentials for Machine Learning. Cambridge: Cambridge University Press

Finio M. & Downie A. (8 December, 2023), IBM What is AI in finance? Available from https://www.ibm.com/topics/artificial-intelligence-finance [Accessed on 15 September 2024] 
IBM, (ND) Available from https://www.ibm.com/topics/decision-trees [Accessed on 4 September 2024]	

McIlrath, B.J., & Kotnour, T. (2002). Process Alignment for Strategic Implementation. Industrial Engineering and Management Systems, University of Central Florida Available from https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=010f80bf420b7d623cf987e5727a0f0574867620 [Accessed on 19 September 2024]

Learn Scikit (ND), Available from https://scikit-learn.org/stable/modules/tree.html [Accessed on 4 September 2024]

Oti, E. et al (2021). Comprehensive Review of K-Means Clustering Algorithms. International Journal of Advances in Scientific Research and Engineering. Available from https://www.researchgate.net/publication/354547481_Comprehensive_Review_of_K-Means_Clustering_Algorithms [Accessed on 9 September 2024]

Nishan, J. (26 May 2023) Mastering data clustering: Your comprehensive guide to K-means and K-means++, AI Accelerator Institute. Available from https://www.aiacceleratorinstitute.com/mastering-data-clustering-your-comprehensive-guide-to-k-means-and-k-means/ [Accessed on 9 September 2024)

PEX Network (11 July, 2024) How AI is transforming financial services: Key roles and functions Available from https://www.processexcellencenetwork.com/ai/articles/ai-transforming-financial-services [Accessed on 15 September]

Poree J. (23 September 2022), Nexus FrontierTex How Do I Identify Valid Use Cases for AI Within My Enterprise? Available from hhttps://nexusfrontier.tech/how-do-i-identify-valid-use-cases-for-ai-within-my-enterprise/ [Accessed on 12 September 2024]

Russell, S, & Norvig, (2021), Artificial Intelligence: a Modern Approach, Global Edition, Pearson Education, Limited, Harlow. Available from: ProQuest Ebook Central. [Accessed on 19 September 2024].

Suyal, M. & Sharma, S. (2024) A Review on Analysis of K-Means Clustering Machine Learning Algorithm based on Unsupervised Learning. Journal of Artificial Intelligence and Systems. Available from https://www.researchgate.net/publication/379878557_A_Review_on_Analysis_of_K-Means_Clustering_Machine_Learning_Algorithm_based_on_Unsupervised_Learning [Accessed on 8 September]

Song YY, Lu Y. (25 April 2015), Decision tree methods: applications for classification and prediction. Shanghai Arch Psychiatry. 27(2):130-5. DOI: 10.11919/j.issn.1002-0829.215044
Terence Tse et al.  (29 April, 2021) Five steps for companies to make AI pilots a success Available from https://blogs.lse.ac.uk/businessreview/2021/04/29/five-steps-for-companies-to-make-ai-pilots-a-success/ [Accessed on 14 September 2024]

University of Oxford (2023), Artificial Intelligence Programme, Module 6, Unit 2 Infographic Transcript 

Anon (ND), Revolutionizing Finance: The AI in Finance Advantage, Available from https://www.onestream.com/blog/ai-in-finance/ [Accessed on 19 September 2024]

[Back to the top](#understanding-artificial-intelligence)


## Artificial Intelligence (AI) Solution Implementation

**Assignment Details**

**You are required to carry out an experiment using the WEKA software tool and the appropriate dataset available at UCI or Kaggle. You will need to demonstrate to the senior management of the start-up company discussed in Unit 9, the feasibility of the AI technology deployment in at least one of the key areas you identified in your Unit 9 report. It does not have to be an exact solution, but you must demonstrate the application of the idea and how the approach and methods of the experiment can be transferred.**

**Implementation report**

I. Business context

Following the previous report of the IT department concerning the need for our start-up finance company to embrace Artificial Intelligence (AI) enabled tools in its operations, with this implementation report, we would like to demonstrate the feasibility of AI deployment, which will aim to enhance our competitiveness and improve our market share.  
As previously discussed, there is a pressing need for our company to endorse a series of AI-enabled tools concerning three key areas: i) day-to-day business/customer operations (forwarding phone calls/emails to the competent department, smooth handling of complaints) ii) automatic credit risk analysis, scoring and loan approval and finally iii) proactive targeting of customers based on their profile through personalised recommendations for financial products/services.  To better illustrate the case for the feasibility of the AI-deployment, my department has explored how we could deploy AI-solutions in one of the aforementioned key areas, namely the credit risk analysis for loan applicants.   As already stressed, for this key area we propose making use of supervised learning methods and, in particular, of Decision Tree (DT) algorithms.   Our concept project has benefited from the CRISP-DM process model (Cross-Industry Standard Process for Data Mining) and its process model descriptions: a. business understanding, b. data understanding, c. data preparation, d. modelling, e. evaluation and f. deployment (Schröer et al., 2021).

II. Justification of the dataset choice 

To analyse the credit risk/scoring of loan applicants and find out what type of data is required for the final decision to grant/reject a loan application, we have primarily based our proposal on the domain knowledge of colleagues working in the department responsible for processing loan applications.  The datasets, which are valuable for the ‘manual’ processing and could be used to feed in the algorithmic model, in order to predict the credit risk of loan applicants, are the following: corporate/individual loan applicant status, gender, marital status, education, turnover for companies/yearly income for individuals, property value, default cases in the past, cases of delay in paying back instalments, level of securities, the purpose of the loan (service/investment/goods), the level of yearly tax returns, the level of existing private debts or of debts to the state authorities as well as pending mortgage/credit card debts.  

Some of this data could be filled in on our company software application by the loan applicants themselves, whereas the most crucial ones, following their consent, could be retrieved, via interoperability methods, from the intra-banking system and the tax authorities’ databases.  We cannot now argue that all the above datasets will be required for our envisaged model, however, all dataset categories add information in the loan application procedure.  After having applied the model and evaluated its results, we will be better placed to decide which of the data will be absolutely required.

The above process of selecting the appropriate datasets constitutes a part of feature engineering, ‘which include feature selection and extraction to reduce data dimensionality and eliminate redundancy and noise’ (Wang et al., 2021).  Choosing the appropriate subset of attributes means optimally reducing the volume of the existing data, according to the defined criteria set already by the responsible department (knowledge-based selection).  The primary purpose of such selection is to enhance the accuracy of the model prediction by discarding characteristics with little impact and by retaining at the same time the characteristics having an added value (Wang et al., 2021).  


III. Justification of the approach to developing the prediction model

Given that the factors of creditworthiness are already known by the company experts, we proposed for this AI-solution the use of the supervised learning method.  The model, which will be fed in by a number of attribute values with an information gain, is expected to result to two main prediction outcomes: 

i)	cases of loan applicants with a high level of creditworthiness, where the model will advise in favour of the loan approval (Class: Yes) and 

ii)	cases of loan applicants with a dubious creditworthiness level, where the model will advise against granting a loan (Class: No).  

There might also be cases somewhere in the middle of these extremes, where loan applicants may have experienced some minor financial problems in the past, which do not make them qualify to the creditworthy customers, so further research/cross-checking should follow before the final decision is made (loan approval/rejection).   

Nevertheless, according to our project, the envisaged AI-solution will only augment human capacity, because human intervention will continue being necessary for loan approval or rejection (Bowman, 2024; PEX, 2024; Deloitte, ND; IBM, ND).  As explained in our initial report, given that ‘AI algorithms can analyse vast amounts of data to identify patterns and assess creditworthiness more accurately, […] this can lead to fewer loan defaults, reduced risk provisions, and improved profit margins, […] (Chlouverakis, 2024).  

Our AI-model will be further tested/evaluated so that ‘false positives/FP’ and ‘false negatives/FN’, due to algorithmic bias, data misuse, data privacy and security infringements, are avoided to the extent possible.  To give you an example of algorithmic bias, people from a given social, ethnic, social background may be biased, offered a higher interest rate for the loan applicant or asked for a higher value security in comparison to other potential customers of the same creditworthiness level (Archontas, 2024).  To improve our competitiveness and market share, we must avoid cases of FP as much as possible, while the existence of FN is less problematic, as these instances will be further examined by the responsible department (Specificity/accuracy indicator). Granting loans to FPs will jeopardise our survival and will have an adverse effect on the company assets’ value.

IV. Rationale for the machine learning algorithms used

We propose to make use of the Decision Tree (DT) algorithmic model, which constitutes a straightforward, easy-to-see and interpret algorithm of supervised learning with a high degree of explicability and replicability.  A DT uses labelled input and datasets for output to train a model and consists of a root, internal nodes and leaves.  ‘The internal nodes of the tree represent a test on an attribute or subset of attributes’ (Cohen, 2021).   DTs can easily classify data and predict the outcome based on the training data; this is why the model is suitable for us to deploy for the credit risk analysis/scoring/loan approval.

In the initial report, we pointed out that DTs are simple to understand as they can be visualised, can process numerical/categorical data, may support a certain degree of explainability contrary to the ‘black box’ of artificial neural network and they require little to no data preparation (Learn Scikit, ND).   While DTs for credit risk analysis may be effective and efficient, we have to take into account that DTs can become overly complex as they cannot generalise well to new data (overfitting) and even slight variations can deliver a different outcome (IBM, ND).   This is the reason why DTs are considered as unstable, in the sense that once an attribute value is modified, the outcome may be also modified.  
To illustrate our AI-solution proposal, we used open data with similar characteristics to our business available on Kaggle.  More concretely, we used the data file Credit_risk_customers (file in .csv format https://www.kaggle.com/datasets/ppb00x/credit-risk-customers )

This dataset consists of 20 features of 1 000 customers/instances and could be used to predict if the loan applicant could be given credit (good/bad credit risk).  The 20 features/attributes of the file are the following: checking status, duration, credit history, purpose, credit amount, savings status, employment, instalment commitment, personal status, other parties, residence since, property magnitude, age, other payment plans, housing, existing credits, job, number of dependents, own telephone, foreign worker, class.

For the sake of our pilot project run in a testing environment, we selected 9 features, which are significant from the domain knowledge point of view and subsequently removed/discarded the remaining ones, as we considered that they do not provide much added value.  After discarding the redundant features, we kept the initial 1 000 instances with 10 features (9 attributes and 1 class): checking status, duration, credit history, credit amount, savings status, employment, other payment plans, housing, existing credits, class/outcome.

V. Analysis of the outputs

For our analysis, we used the WEKA tool and deployed the Classification functionality, the Decision Tree and the J48 algorithmic model (Annex).  Significant tests were carried out to examine the performance differences between the prediction models.  We performed six (J48) experiments and tested their validity and accuracy with different WEKA parameters: 

i)	unpruned vs. pruned tree, 

ii)	cross-validation 10-20, 

iii)	minNumObj 2-10 

iv)	tree visualisation 

(screenshots of the six model experiments can be found in the Annex)

A.	unpruned tree, cross-validation 10, minNumObj2

B.	unpruned tree, cross-validation 20, minNumObj2

C.	pruned tree, cross-validation 10, minNumObj2

D.	pruned tree, cross-validation 20, minNumObj2

E.	pruned tree, cross-validation 10, minNumObj 10

F.	pruned tree, cross-validation 20, minNumObj 10

Our assumption is that DTs should have limited number of leaves, so the visualisation is facilitated.  If this is not the case due to multiple features, we tried tree pruning.  

1. The model of unpruned tree with cross validation 10 and minNumObj2 produced an unpruned tree with 218 leaves (313 size of tree), with a percentage of 70.4% correctly classified instances vs. 29.6% of incorrectly classified instances.  The tree visualisation seems unmanageable and not clear enough.
2.The model of unpruned tree with cross validation 20 and minNumObj 2, produced an unpruned tree with 218 leaves (313 size of tree) and classified correctly 70.5% of the instances vs. 29.5% of incorrectly classified instances.  The tree visualisation seems again unmanageable and not clear enough.
3. The model of pruned tree with cross-validation 10 and minNumObj 2 produced a pruned tree with 60 leaves (92 size of tree) and 72.8% correctly classified instances vs. 27.2% incorrectly classified instances. Tree visualisation is improved, but it remains unclear.
4. The model of pruned tree with cross-validation 20 and minNumObj 2 produced a pruned tree with 60 leaves (92 size of tree), and 74.2% correctly classified instances vs. 25.8% incorrectly classified instances.  Although accuracy reaches the highest level out of the six experiments, nevertheless, the tree visualisation is not straightforward and does not help.
5. The model of pruned tree with cross-validation 10 and minNumObj 10 produced a pruned tree with 17 leaves (24 size of tree) and 73.4% of correctly classified instances vs. 26.6% of incorrectly classified instances.  The tree visualisation seems improved and can be easily consulted.
6. The model of pruned tree with cross-validation 20 and minNumObj 10, produced a pruned tree with 17 leaves (24 size of tree) and 74% of correctly classified instances vs. 26% incorrectly classified instances.  The tree visualisation is straightforward, and the accuracy level is quite high (74%), although not as high as the model experiment 4 (74.2%).
However, given the simplicity of the tree and the particularly high level of accuracy in detecting correctly classified instances, we suggest adopting this model algorithm.  

Due to the imbalance of the instances, we applied SMOTE (Synthetic Minority Oversampling Technique)/Randomise filters (see the results in the Annex, pp. 22-25).

VI. Demonstration that the application of the approach/methods can be applied to the identified problem 

As Foody (2023) pointed out, it is of utmost importance for the classification quality to what extent the model predictions are accurate.  The term ‘classification accuracy’ denotes the amount of error included in the dataset and shows if the classification model is effective for a particular case.  ‘The error can be calculated by comparing the classifier’s labels with reality.  In practice, the labels predicted by the classifier are compared against those obtained from a reference standard’. 
If the accuracy does not reach a sufficient level, this might constitute the rationale for further fine-tuning the parameters and enhancing the classifier model.  If the accuracy level remains low, we are obliged to discard the classifier model and choose another one which performs better (Foody, 2023).  This is why we tested six models and found out, following fine-tuning of the parameters of the J48 model (WEKA tool), that the best prediction outcomes and tree visualisation are produced by the model 6.  

![image](https://github.com/user-attachments/assets/637ecb45-7921-4b01-b9f2-7555fca93eaa)

When making use of the CRISP-DM process model and in particular when performing the modelling, the evaluation and deployment phases of the envisaged AI-solution, we must avoid a high rate of False Positives (FP) to prevent our finance company from granting loans to non-creditworthy loan applicants.  On the other hand, it is in our company best interest to seek a high rate of True Negatives (TN), cases that were classed as negative and also have a negative label in the reference data.  The determining factor for choosing the appropriate model algorithm should be ‘inverse recall’/‘specificity’.  This term defines the proportion of real negative cases that are correctly predicted negative (True Negative Rate/tnr) (Powers, 2007).

![image](https://github.com/user-attachments/assets/21956226-9ad8-437d-953e-873444e257ca)

Having said the above, a bigger sample size will be required to further update and evaluate the suggested model, given that, for experiment purposes, we used datasets from the Kaggle repository and not our own.  We believe that with further development and validation, our prediction modelling algorithm will enable us to successfully analyse the credit risk of loan applicants and therefore to support and speed up the loan approval process.
 

**References**

Archontas N. (2024), Artificial Intelligence and its applications, Individual Essay, Module 1, Understanding Artificial Intelligence, UoEO

Bowman J. (20 August, 2024) How Artificial Intelligence is Used in Finance Learn how AI is transforming the financial sector Available from https://www.fool.com/investing/stock-market/market-sectors/information-technology/ai-stocks/ai-in-finance/#:~:text=AI%20is%20being%20used%20in,insurance%2C%20and%20even%20customer%20service [Accessed on 15 September 2024]

Chlouverakis K. (26 April, 2024) How artificial intelligence is reshaping the financial services industry Available from https://www.ey.com/en_gr/financial-services/how-artificial-intelligence-is-reshaping-the-financial-services-industry [Accessed on 10 September 2024]

Cohen S. MD (2021) Chapter 2: The basics of machine learning: strategies and techniques, Artificial Intelligence and Deep Learning in Pathology. Available from https://www.sciencedirect.com/topics/computer-science/decision-tree-algorithm [Accessed on 3 September 2024]

Deloitte (ND), How Artificial Intelligence is Transforming the Financial Services Industry Available from https://www.deloitte.com/ng/en/services/risk-advisory/services/how-artificial-intelligence-is-transforming-the-financial-services-industry.html [Accessed on 18 September 2024]

Foody, G. M. & Huang, S. (2023) Challenges in the real world use of classification accuracy metrics: From recall and precision to the Matthews correlation coefficient. PloS one 18 (10): e0291908–e0291908. Available from https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0291908 [Accessed on 5 October 2024]

IBM, (ND) Available from https://www.ibm.com/topics/decision-trees [Accessed on 4 September 2024]	

Learn Scikit (ND), Available from https://scikit-learn.org/stable/modules/tree.html [Accessed on 4 September 2024]

PEX Network (11 July, 2024) How AI is transforming financial services: Key roles and functions Available from https://www.processexcellencenetwork.com/ai/articles/ai-transforming-financial-services [Accessed on 15 September]

Powers, D.M.W. (2007), Evaluation: from precision, recall and F-measure to ROC, Informedness, Markedness & Correlation, *AILab, School of Computer Science, Engineering and Mathematics, Flinders University, South Australia, Australia Available from https://www.researchgate.net/publication/228529307_Evaluation_From_Precision_Recall_and_F-Factor_to_ROC_Informedness_Markedness_Correlation [Accessed on 10 October 2024]

Schröer, C., Kruse, F. & Gomez, J.M. (2021) A Systematic Literature Review on Applying CRISP-DM Process Model. Procedia computer science. 181526–534. Available from https://www.sciencedirect.com/science/article/pii/S1877050921002416?via%3Dihub [Accessed on 5 October 2024]

Wang, Z., Xia, L., Yuan, H., Srinivasan, R.S. & Song, X. (2022) Principles, research status, and prospects of feature engineering for data-driven building energy prediction: A comprehensive review. Journal of Building Engineering. 58105028.

WEKA (Waikato Environment for Knowledge Analysis) tool Available from https://www.waikato.ac.nz/int/research/institutes-centres-entities/institutes/artificial-intelligence-institute/research/software/

[Back to the top](#understanding-artificial-intelligence)

[Go to main Menu](https://narchondas.github.io/)
